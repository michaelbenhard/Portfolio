{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "098f6e49-1d4b-428f-990e-455deab611cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a12e57-70fd-4c95-8c37-f4867371a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95313477-91df-4a76-bfe3-d1489a83a58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/09 22:58:18 WARN Utils: Your hostname, Benhards-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.1.14 instead (on interface en0)\n",
      "23/07/09 22:58:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/09 22:58:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/07/09 22:58:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('DataFrame').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dce0916-8bf1-4b4b-b53e-5390d8892efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.14:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10ec25490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9958038-1114-49be-ab83-6509659e7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "df_pyspark = spark.read.option('header','true').csv('data.csv', inferSchema = True)\n",
    "#inferSchema argument is to make sure the schema does not end up in all string form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d1b01a-5447-4801-9253-cbc45ce079bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name : string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f25961-3cea-4d82-b3f8-c0f276571f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "|Michael| 21|        10|\n",
      "|  Karen| 22|         8|\n",
      "| Jessie| 20|         4|\n",
      "+-------+---+----------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('data.csv', header = True, inferSchema = True)\n",
    "df_pyspark.show()\n",
    "df_pyspark.printSchema()\n",
    "#Same as before, different syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f9a9791-6c82-47a0-9b36-43bb89115523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7231cba-09cf-4e39-a095-9fa3d016ccf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Michael', Age=21, Experience=10),\n",
       " Row(Name='Karen', Age=22, Experience=8),\n",
       " Row(Name='Jessie', Age=20, Experience=4)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns\n",
    "#Show the columns in a dataframe\n",
    "df_pyspark.head(3)\n",
    "#Show first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0a87508-8f11-4390-b9aa-dfc5d1c4f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "|Michael|\n",
      "|  Karen|\n",
      "| Jessie|\n",
      "+-------+\n",
      "\n",
      "+-------+----------+\n",
      "|   Name|Experience|\n",
      "+-------+----------+\n",
      "|Michael|        10|\n",
      "|  Karen|         8|\n",
      "| Jessie|         4|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name').show()\n",
    "#Show only the 'Name' column\n",
    "df_pyspark.select(['Name','Experience']).show()\n",
    "#Show 'Name' and 'Experience' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b12a4e89-0e19-463a-91b9-7abf33fb5e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes\n",
    "#Show types of data in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5d341b4-af90-4150-9efe-60e846a1e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+-----------------+\n",
      "|summary|   Name| Age|       Experience|\n",
      "+-------+-------+----+-----------------+\n",
      "|  count|      3|   3|                3|\n",
      "|   mean|   null|21.0|7.333333333333333|\n",
      "| stddev|   null| 1.0|3.055050463303893|\n",
      "|    min| Jessie|  20|                4|\n",
      "|    max|Michael|  22|               10|\n",
      "+-------+-------+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81f92ce6-88b7-4abc-9704-b741e8b2b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------------------------+\n",
      "|   Name|Age|Experience|Experience After 2 Years|\n",
      "+-------+---+----------+------------------------+\n",
      "|Michael| 21|        10|                      12|\n",
      "|  Karen| 22|         8|                      10|\n",
      "| Jessie| 20|         4|                       6|\n",
      "+-------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding column\n",
    "df_pyspark = df_pyspark.withColumn('Experience After 2 Years', df_pyspark['Experience']+2)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f04b4c91-31f6-44f7-81cc-ef0c70dbae94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "|Michael| 21|        10|\n",
      "|  Karen| 22|         8|\n",
      "| Jessie| 20|         4|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Dropping columns\n",
    "df_pyspark = df_pyspark.drop('Experience After 2 years')\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d39da62-7c6e-4905-872a-3322cf764375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|New Name|Age|Experience|\n",
      "+--------+---+----------+\n",
      "| Michael| 21|        10|\n",
      "|   Karen| 22|         8|\n",
      "|  Jessie| 20|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Renaming columns\n",
    "df_pyspark.withColumnRenamed('Name','New Name').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
